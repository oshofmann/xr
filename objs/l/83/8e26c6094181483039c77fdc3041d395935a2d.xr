var __xr_tmp = [
"<span class=\"comment\"> * match the requested limits. See gfp_zone() in include/linux/gfp.h</span>", 
"<span class=\"comment\"> */</span>", 
"", 
"#if <a class=\"id\" href=\"#MAX_NR_ZONES\">MAX_NR_ZONES</a> &lt; 2", 
"#<a class=\"id\" href=\"#define\">define</a> <a class=\"id\" href=\"#ZONES_SHIFT\">ZONES_SHIFT</a> 0", 
"#<a class=\"id\" href=\"#elif\">elif</a> <a class=\"id\" href=\"#MAX_NR_ZONES\">MAX_NR_ZONES</a> <= 2", 
"#<a class=\"id\" href=\"#define\">define</a> <a class=\"id\" href=\"#ZONES_SHIFT\">ZONES_SHIFT</a> 1", 
"#<a class=\"id\" href=\"#elif\">elif</a> <a class=\"id\" href=\"#MAX_NR_ZONES\">MAX_NR_ZONES</a> <= 4", 
"#<a class=\"id\" href=\"#define\">define</a> <a class=\"id\" href=\"#ZONES_SHIFT\">ZONES_SHIFT</a> 2", 
"#else", 
"#<a class=\"id\" href=\"#error\">error</a> <a class=\"id\" href=\"#ZONES_SHIFT\">ZONES_SHIFT</a> -- <a class=\"id\" href=\"#too\">too</a> <a class=\"id\" href=\"#many\">many</a> <a class=\"id\" href=\"#zones\">zones</a> <a class=\"id\" href=\"#configured\">configured</a> <a class=\"id\" href=\"#adjust\">adjust</a> <a class=\"id\" href=\"#calculation\">calculation</a>", 
"#<a class=\"id\" href=\"#endif\">endif</a>", 
"", 
"struct <a class=\"id\" href=\"#zone_reclaim_stat\">zone_reclaim_stat</a> {", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The pageout code in vmscan.c keeps track of how many of the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * mem/swap backed and file backed pages are refeferenced.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The higher the rotated/scanned ratio, the more valuable</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * that cache is.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The anon LRU stats live in [0], file LRU stats in [1]</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#recent_rotated\">recent_rotated</a>[2];", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#recent_scanned\">recent_scanned</a>[2];", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * accumulated for batching</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#nr_saved_scan\">nr_saved_scan</a>[<a class=\"id\" href=\"#NR_LRU_LISTS\">NR_LRU_LISTS</a>];", 
"};", 
"", 
"struct <a class=\"id\" href=\"#zone\">zone</a> {", 
"<span class=\"ts\"/><span class=\"comment\">/* Fields commonly accessed by the page allocator */</span>", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/* zone watermarks, access with *_wmark_pages(zone) macros */</span>", 
"<span class=\"ts\"/>unsigned long <a class=\"id\" href=\"#watermark\">watermark</a>[<a class=\"id\" href=\"#NR_WMARK\">NR_WMARK</a>];", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * When free pages are below this point, additional steps are taken</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * when reading the number of free pages to avoid per-cpu counter</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * drift allowing watermarks to be breached</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long <a class=\"id\" href=\"#percpu_drift_mark\">percpu_drift_mark</a>;", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * We don't know if the memory that we're going to allocate will be freeable</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * or/and it will be released eventually, so to avoid totally wasting several</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * GB of ram we must reserve some of the lower zone memory (otherwise we risk</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * to run OOM on the lower zones despite there's tons of freeable ram</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * on the higher zones). This array is recalculated at runtime if the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * sysctl_lowmem_reserve_ratio sysctl changes.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#lowmem_reserve\">lowmem_reserve</a>[<a class=\"id\" href=\"#MAX_NR_ZONES\">MAX_NR_ZONES</a>];", 
"", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_NUMA\">CONFIG_NUMA</a>", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#node\">node</a>;", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * zone reclaim becomes active if more unmapped pages exist.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#min_unmapped_pages\">min_unmapped_pages</a>;", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#min_slab_pages\">min_slab_pages</a>;", 
"#<a class=\"id\" href=\"#endif\">endif</a>", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#per_cpu_pageset\">per_cpu_pageset</a> <a class=\"id\" href=\"#__percpu\">__percpu</a> *<a class=\"id\" href=\"#pageset\">pageset</a>;", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * free areas of different sizes</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#spinlock_t\">spinlock_t</a><span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#lock\">lock</a>;", 
"<span class=\"ts\"/>int                     <a class=\"id\" href=\"#all_unreclaimable\">all_unreclaimable</a>; <span class=\"comment\">/* All pages pinned */</span>", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_MEMORY_HOTPLUG\">CONFIG_MEMORY_HOTPLUG</a>", 
"<span class=\"ts\"/><span class=\"comment\">/* see spanned/present_pages for more description */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seqlock_t\">seqlock_t</a><span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#span_seqlock\">span_seqlock</a>;", 
"#<a class=\"id\" href=\"#endif\">endif</a>", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#free_area\">free_area</a><span class=\"ts\"/><a class=\"id\" href=\"#free_area\">free_area</a>[<a class=\"id\" href=\"#MAX_ORDER\">MAX_ORDER</a>];", 
"", 
"#<a class=\"id\" href=\"#ifndef\">ifndef</a> <a class=\"id\" href=\"#CONFIG_SPARSEMEM\">CONFIG_SPARSEMEM</a>", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * Flags for a pageblock_nr_pages block. See pageblock-flags.h.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * In SPARSEMEM, this map is stored in struct mem_section</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/>*<a class=\"id\" href=\"#pageblock_flags\">pageblock_flags</a>;", 
"#<a class=\"id\" href=\"#endif\">endif</a> <span class=\"comment\">/* CONFIG_SPARSEMEM */</span>", 
"", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_COMPACTION\">CONFIG_COMPACTION</a>", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * On compaction failure, 1&lt;&lt;compact_defer_shift compactions</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * are skipped before trying again. The number attempted since</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * last failure is tracked with compact_considered.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned int<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#compact_considered\">compact_considered</a>;", 
"<span class=\"ts\"/>unsigned int<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#compact_defer_shift\">compact_defer_shift</a>;", 
"#<a class=\"id\" href=\"#endif\">endif</a>", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#ZONE_PADDING\">ZONE_PADDING</a>(<a class=\"id\" href=\"#_pad1_\">_pad1_</a>)", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/* Fields commonly accessed by the page reclaim scanner */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#spinlock_t\">spinlock_t</a><span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#lru_lock\">lru_lock</a>;<span class=\"ts\"/>", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#zone_lru\">zone_lru</a> {", 
"<span class=\"ts\"/><span class=\"ts\"/>struct <a class=\"id\" href=\"#list_head\">list_head</a> <a class=\"id\" href=\"#list\">list</a>;", 
"<span class=\"ts\"/>} <a class=\"id\" href=\"#lru\">lru</a>[<a class=\"id\" href=\"#NR_LRU_LISTS\">NR_LRU_LISTS</a>];", 
"", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#zone_reclaim_stat\">zone_reclaim_stat</a> <a class=\"id\" href=\"#reclaim_stat\">reclaim_stat</a>;", 
"", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#pages_scanned\">pages_scanned</a>;<span class=\"ts\"/>   <span class=\"comment\">/* since last reclaim */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#flags\">flags</a>;<span class=\"ts\"/><span class=\"ts\"/>   <span class=\"comment\">/* zone flags, see below */</span>", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/* Zone statistics */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#atomic_long_t\">atomic_long_t</a><span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#vm_stat\">vm_stat</a>[<a class=\"id\" href=\"#NR_VM_ZONE_STAT_ITEMS\">NR_VM_ZONE_STAT_ITEMS</a>];", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The target ratio of ACTIVE_ANON to INACTIVE_ANON pages on</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * this zone's LRU.  Maintained by the pageout code.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned int <a class=\"id\" href=\"#inactive_ratio\">inactive_ratio</a>;", 
"", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#ZONE_PADDING\">ZONE_PADDING</a>(<a class=\"id\" href=\"#_pad2_\">_pad2_</a>)", 
"<span class=\"ts\"/><span class=\"comment\">/* Rarely used or read-mostly fields */</span>", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * wait_table<span class=\"ts\"/><span class=\"ts\"/>-- the array holding the hash table</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * wait_table_hash_nr_entries<span class=\"ts\"/>-- the size of the hash table array</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * wait_table_bits<span class=\"ts\"/>-- wait_table_size == (1 &lt;&lt; wait_table_bits)</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The purpose of all these is to keep track of the people</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * waiting for a page to become available and make them</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * runnable again when possible. The trouble is that this</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * consumes a lot of space, especially when so few things</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * wait on pages at a given time. So instead of using</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * per-page waitqueues, we use a waitqueue hash table.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The bucket discipline is to sleep on the same queue when</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * colliding and wake all in that wait queue when removing.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * When something wakes, it must check to be sure its page is</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * truly available, a la thundering herd. The cost of a</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * collision is great, but given the expected load of the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * table, they should be so rare as to be outweighed by the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * benefits from the saved space.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * __wait_on_page_locked() and unlock_page() in mm/filemap.c, are the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * primary users of these fields, and in mm/page_alloc.c</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * free_area_init_core() performs the initialization of them.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#wait_queue_head_t\">wait_queue_head_t</a><span class=\"ts\"/>* <a class=\"id\" href=\"#wait_table\">wait_table</a>;", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#wait_table_hash_nr_entries\">wait_table_hash_nr_entries</a>;", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#wait_table_bits\">wait_table_bits</a>;", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * Discontig memory support fields.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#pglist_data\">pglist_data</a><span class=\"ts\"/>*<a class=\"id\" href=\"#zone_pgdat\">zone_pgdat</a>;", 
"<span class=\"ts\"/><span class=\"comment\">/* zone_start_pfn == zone_start_paddr &gt;&gt; PAGE_SHIFT */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#zone_start_pfn\">zone_start_pfn</a>;", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * zone_start_pfn, spanned_pages and present_pages are all</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * protected by span_seqlock.  It is a seqlock because it has</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * to be read outside of zone-&gt;lock, and it is done in the main</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * allocator path.  But, it is written quite infrequently.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * The lock is declared along with zone-&gt;lock because it is</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * frequently read in proximity to zone-&gt;lock.  It's good to</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * give them a chance of being in the same cacheline.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#spanned_pages\">spanned_pages</a>;<span class=\"ts\"/><span class=\"comment\">/* total size, including holes */</span>", 
"<span class=\"ts\"/>unsigned long<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#present_pages\">present_pages</a>;<span class=\"ts\"/><span class=\"comment\">/* amount of memory (excluding holes) */</span>", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * rarely used fields:</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>const char<span class=\"ts\"/><span class=\"ts\"/>*<a class=\"id\" href=\"#name\">name</a>;", 
"} <a class=\"id\" href=\"#____cacheline_internodealigned_in_smp\">____cacheline_internodealigned_in_smp</a>;", 
"", 
"typedef enum {", 
"<span class=\"ts\"/><a class=\"id\" href=\"#ZONE_RECLAIM_LOCKED\">ZONE_RECLAIM_LOCKED</a>,<span class=\"ts\"/><span class=\"ts\"/><span class=\"comment\">/* prevents concurrent reclaim */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#ZONE_OOM_LOCKED\">ZONE_OOM_LOCKED</a>,<span class=\"ts\"/><span class=\"ts\"/><span class=\"comment\">/* zone is in OOM killer zonelist */</span>", 
"} <a class=\"id\" href=\"#zone_flags_t\">zone_flags_t</a>;", 
"", 
"static <a class=\"id\" href=\"#inline\">inline</a> void <a class=\"id\" href=\"#zone_set_flag\">zone_set_flag</a>(struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>, <a class=\"id\" href=\"#zone_flags_t\">zone_flags_t</a> <a class=\"id\" href=\"#flag\">flag</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#set_bit\">set_bit</a>(<a class=\"id\" href=\"#flag\">flag</a>, &amp;<a class=\"id\" href=\"#zone\">zone</a>-><a class=\"id\" href=\"#flags\">flags</a>);", 
"}", 
"", 
"static <a class=\"id\" href=\"#inline\">inline</a> int <a class=\"id\" href=\"#zone_test_and_set_flag\">zone_test_and_set_flag</a>(struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>, <a class=\"id\" href=\"#zone_flags_t\">zone_flags_t</a> <a class=\"id\" href=\"#flag\">flag</a>)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#test_and_set_bit\">test_and_set_bit</a>(<a class=\"id\" href=\"#flag\">flag</a>, &amp;<a class=\"id\" href=\"#zone\">zone</a>-><a class=\"id\" href=\"#flags\">flags</a>);", 
"}", 
"", 
"static <a class=\"id\" href=\"#inline\">inline</a> void <a class=\"id\" href=\"#zone_clear_flag\">zone_clear_flag</a>(struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>, <a class=\"id\" href=\"#zone_flags_t\">zone_flags_t</a> <a class=\"id\" href=\"#flag\">flag</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#clear_bit\">clear_bit</a>(<a class=\"id\" href=\"#flag\">flag</a>, &amp;<a class=\"id\" href=\"#zone\">zone</a>-><a class=\"id\" href=\"#flags\">flags</a>);", 
"}", 
"", 
"static <a class=\"id\" href=\"#inline\">inline</a> int <a class=\"id\" href=\"#zone_is_reclaim_locked\">zone_is_reclaim_locked</a>(const struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#test_bit\">test_bit</a>(<a class=\"id\" href=\"#ZONE_RECLAIM_LOCKED\">ZONE_RECLAIM_LOCKED</a>, &amp;<a class=\"id\" href=\"#zone\">zone</a>-><a class=\"id\" href=\"#flags\">flags</a>);", 
"}", 
"", 
"static <a class=\"id\" href=\"#inline\">inline</a> int <a class=\"id\" href=\"#zone_is_oom_locked\">zone_is_oom_locked</a>(const struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#test_bit\">test_bit</a>(<a class=\"id\" href=\"#ZONE_OOM_LOCKED\">ZONE_OOM_LOCKED</a>, &amp;<a class=\"id\" href=\"#zone\">zone</a>-><a class=\"id\" href=\"#flags\">flags</a>);", 
"}", 
"", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_SMP\">CONFIG_SMP</a>", 
"unsigned long <a class=\"id\" href=\"#zone_nr_free_pages\">zone_nr_free_pages</a>(struct <a class=\"id\" href=\"#zone\">zone</a> *<a class=\"id\" href=\"#zone\">zone</a>);", 
"#else", 
"#<a class=\"id\" href=\"#define\">define</a> <a class=\"id\" href=\"#zone_nr_free_pages\">zone_nr_free_pages</a>(<a class=\"id\" href=\"#zone\">zone</a>) <a class=\"id\" href=\"#zone_page_state\">zone_page_state</a>(<a class=\"id\" href=\"#zone\">zone</a>, <a class=\"id\" href=\"#NR_FREE_PAGES\">NR_FREE_PAGES</a>)", 
"#<a class=\"id\" href=\"#endif\">endif</a> <span class=\"comment\">/* CONFIG_SMP */</span>", 
"", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * The \"priority\" of VM scanning is how much of the queues we will scan in one</span>", 
];
xr_frag_insert('l/83/8e26c6094181483039c77fdc3041d395935a2d.xr', __xr_tmp);
