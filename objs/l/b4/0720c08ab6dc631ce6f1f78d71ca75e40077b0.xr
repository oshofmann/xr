var __xr_tmp = [
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#update_tasks_nodemask\">update_tasks_nodemask</a>(<a class=\"id\" href=\"#cp\">cp</a>, <a class=\"id\" href=\"#oldmems\">oldmems</a>, <a class=\"id\" href=\"#NULL\">NULL</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/>}", 
"<span class=\"ts\"/>}", 
"<span class=\"ts\"/><a class=\"id\" href=\"#NODEMASK_FREE\">NODEMASK_FREE</a>(<a class=\"id\" href=\"#oldmems\">oldmems</a>);", 
"}", 
"", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * The top_cpuset tracks what CPUs and Memory Nodes are online,</span>", 
"<span class=\"comment\"> * period.  This is necessary in order to make cpusets transparent</span>", 
"<span class=\"comment\"> * (of no affect) on systems that are actively using CPU hotplug</span>", 
"<span class=\"comment\"> * but making no active use of cpusets.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * This routine ensures that top_cpuset.cpus_allowed tracks</span>", 
"<span class=\"comment\"> * cpu_active_mask on each CPU hotplug (cpuhp) event.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Called within get_online_cpus().  Needs to call cgroup_lock()</span>", 
"<span class=\"comment\"> * before calling generate_sched_domains().</span>", 
"<span class=\"comment\"> */</span>", 
"void <a class=\"id\" href=\"#cpuset_update_active_cpus\">cpuset_update_active_cpus</a>(void)", 
"{", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#sched_domain_attr\">sched_domain_attr</a> *<a class=\"id\" href=\"#attr\">attr</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cpumask_var_t\">cpumask_var_t</a> *<a class=\"id\" href=\"#doms\">doms</a>;", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#ndoms\">ndoms</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_lock\">cgroup_lock</a>();", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_lock\">mutex_lock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cpumask_copy\">cpumask_copy</a>(<a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>.<a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>, <a class=\"id\" href=\"#cpu_active_mask\">cpu_active_mask</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#scan_for_empty_cpusets\">scan_for_empty_cpusets</a>(&amp;<a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#ndoms\">ndoms</a> = <a class=\"id\" href=\"#generate_sched_domains\">generate_sched_domains</a>(&amp;<a class=\"id\" href=\"#doms\">doms</a>, &amp;<a class=\"id\" href=\"#attr\">attr</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_unlock\">cgroup_unlock</a>();", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/* Have scheduler rebuild the domains */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#partition_sched_domains\">partition_sched_domains</a>(<a class=\"id\" href=\"#ndoms\">ndoms</a>, <a class=\"id\" href=\"#doms\">doms</a>, <a class=\"id\" href=\"#attr\">attr</a>);", 
"}", 
"", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_MEMORY_HOTPLUG\">CONFIG_MEMORY_HOTPLUG</a>", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * Keep top_cpuset.mems_allowed tracking node_states[N_HIGH_MEMORY].</span>", 
"<span class=\"comment\"> * Call this routine anytime after node_states[N_HIGH_MEMORY] changes.</span>", 
"<span class=\"comment\"> * See also the previous routine cpuset_track_online_cpus().</span>", 
"<span class=\"comment\"> */</span>", 
"static int <a class=\"id\" href=\"#cpuset_track_online_nodes\">cpuset_track_online_nodes</a>(struct <a class=\"id\" href=\"#notifier_block\">notifier_block</a> *<a class=\"id\" href=\"#self\">self</a>,", 
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/>unsigned long <a class=\"id\" href=\"#action\">action</a>, void *<a class=\"id\" href=\"#arg\">arg</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#NODEMASK_ALLOC\">NODEMASK_ALLOC</a>(<a class=\"id\" href=\"#nodemask_t\">nodemask_t</a>, <a class=\"id\" href=\"#oldmems\">oldmems</a>, <a class=\"id\" href=\"#GFP_KERNEL\">GFP_KERNEL</a>);", 
"", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#oldmems\">oldmems</a> == <a class=\"id\" href=\"#NULL\">NULL</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/>return <a class=\"id\" href=\"#NOTIFY_DONE\">NOTIFY_DONE</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_lock\">cgroup_lock</a>();", 
"<span class=\"ts\"/>switch (<a class=\"id\" href=\"#action\">action</a>) {", 
"<span class=\"ts\"/>case <a class=\"id\" href=\"#MEM_ONLINE\">MEM_ONLINE</a>:", 
"<span class=\"ts\"/><span class=\"ts\"/>*<a class=\"id\" href=\"#oldmems\">oldmems</a> = <a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>.<a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>;", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#mutex_lock\">mutex_lock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>.<a class=\"id\" href=\"#mems_allowed\">mems_allowed</a> = <a class=\"id\" href=\"#node_states\">node_states</a>[<a class=\"id\" href=\"#N_HIGH_MEMORY\">N_HIGH_MEMORY</a>];", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#update_tasks_nodemask\">update_tasks_nodemask</a>(&amp;<a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>, <a class=\"id\" href=\"#oldmems\">oldmems</a>, <a class=\"id\" href=\"#NULL\">NULL</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/>break;", 
"<span class=\"ts\"/>case <a class=\"id\" href=\"#MEM_OFFLINE\">MEM_OFFLINE</a>:", 
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * needn't update top_cpuset.mems_allowed explicitly because</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * scan_for_empty_cpusets() will update it.</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#scan_for_empty_cpusets\">scan_for_empty_cpusets</a>(&amp;<a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/>break;", 
"<span class=\"ts\"/>default:", 
"<span class=\"ts\"/><span class=\"ts\"/>break;", 
"<span class=\"ts\"/>}", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_unlock\">cgroup_unlock</a>();", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#NODEMASK_FREE\">NODEMASK_FREE</a>(<a class=\"id\" href=\"#oldmems\">oldmems</a>);", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#NOTIFY_OK\">NOTIFY_OK</a>;", 
"}", 
"#<a class=\"id\" href=\"#endif\">endif</a>", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_init_smp - initialize cpus_allowed</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Description: Finish top cpuset after cpu, node maps are initialized</span>", 
"<span class=\"comment\"> **/</span>", 
"", 
"void <a class=\"id\" href=\"#__init\">__init</a> <a class=\"id\" href=\"#cpuset_init_smp\">cpuset_init_smp</a>(void)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cpumask_copy\">cpumask_copy</a>(<a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>.<a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>, <a class=\"id\" href=\"#cpu_active_mask\">cpu_active_mask</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#top_cpuset\">top_cpuset</a>.<a class=\"id\" href=\"#mems_allowed\">mems_allowed</a> = <a class=\"id\" href=\"#node_states\">node_states</a>[<a class=\"id\" href=\"#N_HIGH_MEMORY\">N_HIGH_MEMORY</a>];", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#hotplug_memory_notifier\">hotplug_memory_notifier</a>(<a class=\"id\" href=\"#cpuset_track_online_nodes\">cpuset_track_online_nodes</a>, 10);", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cpuset_wq\">cpuset_wq</a> = <a class=\"id\" href=\"#create_singlethread_workqueue\">create_singlethread_workqueue</a>(\"cpuset\");", 
"<span class=\"ts\"/><a class=\"id\" href=\"#BUG_ON\">BUG_ON</a>(!<a class=\"id\" href=\"#cpuset_wq\">cpuset_wq</a>);", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_cpus_allowed - return cpus_allowed mask from a tasks cpuset.</span>", 
"<span class=\"comment\"> * @tsk: pointer to task_struct from which to obtain cpuset-&gt;cpus_allowed.</span>", 
"<span class=\"comment\"> * @pmask: pointer to struct cpumask variable to receive cpus_allowed set.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Description: Returns the cpumask_var_t cpus_allowed of the cpuset</span>", 
"<span class=\"comment\"> * attached to the specified @tsk.  Guaranteed to return some non-empty</span>", 
"<span class=\"comment\"> * subset of cpu_online_map, even if this means going outside the</span>", 
"<span class=\"comment\"> * tasks cpuset.</span>", 
"<span class=\"comment\"> **/</span>", 
"", 
"void <a class=\"id\" href=\"#cpuset_cpus_allowed\">cpuset_cpus_allowed</a>(struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk\">tsk</a>, struct <a class=\"id\" href=\"#cpumask\">cpumask</a> *<a class=\"id\" href=\"#pmask\">pmask</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_lock\">mutex_lock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_lock\">task_lock</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#guarantee_online_cpus\">guarantee_online_cpus</a>(<a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#tsk\">tsk</a>), <a class=\"id\" href=\"#pmask\">pmask</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_unlock\">task_unlock</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"}", 
"", 
"int <a class=\"id\" href=\"#cpuset_cpus_allowed_fallback\">cpuset_cpus_allowed_fallback</a>(struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk\">tsk</a>)", 
"{", 
"<span class=\"ts\"/>const struct <a class=\"id\" href=\"#cpuset\">cpuset</a> *<a class=\"id\" href=\"#cs\">cs</a>;", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#cpu\">cpu</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#rcu_read_lock\">rcu_read_lock</a>();", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cs\">cs</a> = <a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#cs\">cs</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#cpumask_copy\">cpumask_copy</a>(&amp;<a class=\"id\" href=\"#tsk\">tsk</a>-><a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>, <a class=\"id\" href=\"#cs\">cs</a>-><a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#rcu_read_unlock\">rcu_read_unlock</a>();", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * We own tsk-&gt;cpus_allowed, nobody can change it under us.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * But we used cs &amp;&amp; cs-&gt;cpus_allowed lockless and thus can</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * race with cgroup_attach_task() or update_cpumask() and get</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * the wrong tsk-&gt;cpus_allowed. However, both cases imply the</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * subsequent cpuset_change_cpumask()-&gt;set_cpus_allowed_ptr()</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * which takes task_rq_lock().</span>", 
"<span class=\"comment\"><span class=\"ts\"/> *</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * If we are called after it dropped the lock we must see all</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * changes in tsk_cs()-&gt;cpus_allowed. Otherwise we can temporary</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * set any mask even if it is not right from task_cs() pov,</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * the pending set_cpus_allowed_ptr() will fix things.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cpu\">cpu</a> = <a class=\"id\" href=\"#cpumask_any_and\">cpumask_any_and</a>(&amp;<a class=\"id\" href=\"#tsk\">tsk</a>-><a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>, <a class=\"id\" href=\"#cpu_active_mask\">cpu_active_mask</a>);", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#cpu\">cpu</a> >= <a class=\"id\" href=\"#nr_cpu_ids\">nr_cpu_ids</a>) {", 
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * Either tsk-&gt;cpus_allowed is wrong (see above) or it</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * is actually empty. The latter case is only possible</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * if we are racing with remove_tasks_in_empty_cpuset().</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * Like above we can temporary set any mask and rely on</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> * set_cpus_allowed_ptr() as synchronization point.</span>", 
"<span class=\"comment\"><span class=\"ts\"/><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#cpumask_copy\">cpumask_copy</a>(&amp;<a class=\"id\" href=\"#tsk\">tsk</a>-><a class=\"id\" href=\"#cpus_allowed\">cpus_allowed</a>, <a class=\"id\" href=\"#cpu_possible_mask\">cpu_possible_mask</a>);", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#cpu\">cpu</a> = <a class=\"id\" href=\"#cpumask_any\">cpumask_any</a>(<a class=\"id\" href=\"#cpu_active_mask\">cpu_active_mask</a>);", 
"<span class=\"ts\"/>}", 
"", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#cpu\">cpu</a>;", 
"}", 
"", 
"void <a class=\"id\" href=\"#cpuset_init_current_mems_allowed\">cpuset_init_current_mems_allowed</a>(void)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#nodes_setall\">nodes_setall</a>(<a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_mems_allowed - return mems_allowed mask from a tasks cpuset.</span>", 
"<span class=\"comment\"> * @tsk: pointer to task_struct from which to obtain cpuset-&gt;mems_allowed.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Description: Returns the nodemask_t mems_allowed of the cpuset</span>", 
"<span class=\"comment\"> * attached to the specified @tsk.  Guaranteed to return some non-empty</span>", 
"<span class=\"comment\"> * subset of node_states[N_HIGH_MEMORY], even if this means going outside the</span>", 
"<span class=\"comment\"> * tasks cpuset.</span>", 
"<span class=\"comment\"> **/</span>", 
"", 
"<a class=\"id\" href=\"#nodemask_t\">nodemask_t</a> <a class=\"id\" href=\"#cpuset_mems_allowed\">cpuset_mems_allowed</a>(struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk\">tsk</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#nodemask_t\">nodemask_t</a> <a class=\"id\" href=\"#mask\">mask</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_lock\">mutex_lock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_lock\">task_lock</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#guarantee_online_mems\">guarantee_online_mems</a>(<a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#tsk\">tsk</a>), &amp;<a class=\"id\" href=\"#mask\">mask</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_unlock\">task_unlock</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#mask\">mask</a>;", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_nodemask_valid_mems_allowed - check nodemask vs. curremt mems_allowed</span>", 
"<span class=\"comment\"> * @nodemask: the nodemask to be checked</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Are any of the nodes in the nodemask allowed in current-&gt;mems_allowed?</span>", 
"<span class=\"comment\"> */</span>", 
"int <a class=\"id\" href=\"#cpuset_nodemask_valid_mems_allowed\">cpuset_nodemask_valid_mems_allowed</a>(<a class=\"id\" href=\"#nodemask_t\">nodemask_t</a> *<a class=\"id\" href=\"#nodemask\">nodemask</a>)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#nodes_intersects\">nodes_intersects</a>(*<a class=\"id\" href=\"#nodemask\">nodemask</a>, <a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"}", 
"", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * nearest_hardwall_ancestor() - Returns the nearest mem_exclusive or</span>", 
"<span class=\"comment\"> * mem_hardwall ancestor to the specified cpuset.  Call holding</span>", 
"<span class=\"comment\"> * callback_mutex.  If no ancestor is mem_exclusive or mem_hardwall</span>", 
"<span class=\"comment\"> * (an unusual configuration), then returns the root cpuset.</span>", 
"<span class=\"comment\"> */</span>", 
"static const struct <a class=\"id\" href=\"#cpuset\">cpuset</a> *<a class=\"id\" href=\"#nearest_hardwall_ancestor\">nearest_hardwall_ancestor</a>(const struct <a class=\"id\" href=\"#cpuset\">cpuset</a> *<a class=\"id\" href=\"#cs\">cs</a>)", 
"{", 
"<span class=\"ts\"/>while (!(<a class=\"id\" href=\"#is_mem_exclusive\">is_mem_exclusive</a>(<a class=\"id\" href=\"#cs\">cs</a>) || <a class=\"id\" href=\"#is_mem_hardwall\">is_mem_hardwall</a>(<a class=\"id\" href=\"#cs\">cs</a>)) && <a class=\"id\" href=\"#cs\">cs</a>-><a class=\"id\" href=\"#parent\">parent</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#cs\">cs</a> = <a class=\"id\" href=\"#cs\">cs</a>-><a class=\"id\" href=\"#parent\">parent</a>;", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#cs\">cs</a>;", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_node_allowed_softwall - Can we allocate on a memory node?</span>", 
"<span class=\"comment\"> * @node: is this an allowed node?</span>", 
"<span class=\"comment\"> * @gfp_mask: memory allocation flags</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * If we're in interrupt, yes, we can always allocate.  If __GFP_THISNODE is</span>", 
"<span class=\"comment\"> * set, yes, we can always allocate.  If node is in our task's mems_allowed,</span>", 
"<span class=\"comment\"> * yes.  If it's not a __GFP_HARDWALL request and this node is in the nearest</span>", 
"<span class=\"comment\"> * hardwalled cpuset ancestor to this task's cpuset, yes.  If the task has been</span>", 
"<span class=\"comment\"> * OOM killed and has access to memory reserves as specified by the TIF_MEMDIE</span>", 
"<span class=\"comment\"> * flag, yes.</span>", 
"<span class=\"comment\"> * Otherwise, no.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * If __GFP_HARDWALL is set, cpuset_node_allowed_softwall() reduces to</span>", 
"<span class=\"comment\"> * cpuset_node_allowed_hardwall().  Otherwise, cpuset_node_allowed_softwall()</span>", 
"<span class=\"comment\"> * might sleep, and might allow a node from an enclosing cpuset.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * cpuset_node_allowed_hardwall() only handles the simpler case of hardwall</span>", 
"<span class=\"comment\"> * cpusets, and never sleeps.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * The __GFP_THISNODE placement logic is really handled elsewhere,</span>", 
"<span class=\"comment\"> * by forcibly using a zonelist starting at a specified node, and by</span>", 
"<span class=\"comment\"> * (in get_page_from_freelist()) refusing to consider the zones for</span>", 
"<span class=\"comment\"> * any node on the zonelist except the first.  By the time any such</span>", 
"<span class=\"comment\"> * calls get to this routine, we should just shut up and say 'yes'.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * GFP_USER allocations are marked with the __GFP_HARDWALL bit,</span>", 
"<span class=\"comment\"> * and do not allow allocations outside the current tasks cpuset</span>", 
"<span class=\"comment\"> * unless the task has been OOM killed as is marked TIF_MEMDIE.</span>", 
"<span class=\"comment\"> * GFP_KERNEL allocations are not so marked, so can escape to the</span>", 
"<span class=\"comment\"> * nearest enclosing hardwalled ancestor cpuset.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Scanning up parent cpusets requires callback_mutex.  The</span>", 
"<span class=\"comment\"> * __alloc_pages() routine only calls here with __GFP_HARDWALL bit</span>", 
"<span class=\"comment\"> * _not_ set if it's a GFP_KERNEL allocation, and all nodes in the</span>", 
"<span class=\"comment\"> * current tasks mems_allowed came up empty on the first pass over</span>", 
"<span class=\"comment\"> * the zonelist.  So only GFP_KERNEL allocations, if all nodes in the</span>", 
"<span class=\"comment\"> * cpuset are short of memory, might require taking the callback_mutex</span>", 
"<span class=\"comment\"> * mutex.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * The first call here from mm/page_alloc:get_page_from_freelist()</span>", 
"<span class=\"comment\"> * has __GFP_HARDWALL set in gfp_mask, enforcing hardwall cpusets,</span>", 
"<span class=\"comment\"> * so no allocation on a node outside the cpuset is allowed (unless</span>", 
"<span class=\"comment\"> * in interrupt, of course).</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * The second pass through get_page_from_freelist() doesn't even call</span>", 
"<span class=\"comment\"> * here for GFP_ATOMIC calls.  For those calls, the __alloc_pages()</span>", 
"<span class=\"comment\"> * variable 'wait' is not set, and the bit ALLOC_CPUSET is not set</span>", 
"<span class=\"comment\"> * in alloc_flags.  That logic and the checks below have the combined</span>", 
"<span class=\"comment\"> * affect that:</span>", 
"<span class=\"comment\"> *<span class=\"ts\"/>in_interrupt - any node ok (current task context irrelevant)</span>", 
"<span class=\"comment\"> *<span class=\"ts\"/>GFP_ATOMIC   - any node ok</span>", 
"<span class=\"comment\"> *<span class=\"ts\"/>TIF_MEMDIE   - any node ok</span>", 
"<span class=\"comment\"> *<span class=\"ts\"/>GFP_KERNEL   - any node in enclosing hardwalled cpuset ok</span>", 
"<span class=\"comment\"> *<span class=\"ts\"/>GFP_USER     - only nodes in current tasks mems allowed ok.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Rule:</span>", 
"<span class=\"comment\"> *    Don't call cpuset_node_allowed_softwall if you can't sleep, unless you</span>", 
"<span class=\"comment\"> *    pass in the __GFP_HARDWALL flag set in gfp_flag, which disables</span>", 
"<span class=\"comment\"> *    the code that might scan up ancestor cpusets and sleep.</span>", 
"<span class=\"comment\"> */</span>", 
"int <a class=\"id\" href=\"#__cpuset_node_allowed_softwall\">__cpuset_node_allowed_softwall</a>(int <a class=\"id\" href=\"#node\">node</a>, <a class=\"id\" href=\"#gfp_t\">gfp_t</a> <a class=\"id\" href=\"#gfp_mask\">gfp_mask</a>)", 
"{", 
"<span class=\"ts\"/>const struct <a class=\"id\" href=\"#cpuset\">cpuset</a> *<a class=\"id\" href=\"#cs\">cs</a>;<span class=\"ts\"/><span class=\"comment\">/* current cpuset ancestors */</span>", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#allowed\">allowed</a>;<span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/><span class=\"comment\">/* is allocation in zone z allowed? */</span>", 
"", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#in_interrupt\">in_interrupt</a>() || (<a class=\"id\" href=\"#gfp_mask\">gfp_mask</a> &amp; <a class=\"id\" href=\"#__GFP_THISNODE\">__GFP_THISNODE</a>))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#might_sleep_if\">might_sleep_if</a>(!(<a class=\"id\" href=\"#gfp_mask\">gfp_mask</a> &amp; <a class=\"id\" href=\"#__GFP_HARDWALL\">__GFP_HARDWALL</a>));", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#node_isset\">node_isset</a>(<a class=\"id\" href=\"#node\">node</a>, <a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * Allow tasks that have access to memory reserves because they have</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * been OOM killed to get memory anywhere.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#unlikely\">unlikely</a>(<a class=\"id\" href=\"#test_thread_flag\">test_thread_flag</a>(<a class=\"id\" href=\"#TIF_MEMDIE\">TIF_MEMDIE</a>)))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#gfp_mask\">gfp_mask</a> &amp; <a class=\"id\" href=\"#__GFP_HARDWALL\">__GFP_HARDWALL</a>)<span class=\"ts\"/><span class=\"comment\">/* If hardwall request, stop here */</span>", 
"<span class=\"ts\"/><span class=\"ts\"/>return 0;", 
"", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#flags\">flags</a> &amp; <a class=\"id\" href=\"#PF_EXITING\">PF_EXITING</a>) <span class=\"comment\">/* Let dying task have memory */</span>", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"", 
"<span class=\"ts\"/><span class=\"comment\">/* Not hardwall and node outside mems_allowed: scan up cpusets */</span>", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_lock\">mutex_lock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_lock\">task_lock</a>(<a class=\"id\" href=\"#current\">current</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cs\">cs</a> = <a class=\"id\" href=\"#nearest_hardwall_ancestor\">nearest_hardwall_ancestor</a>(<a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#current\">current</a>));", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_unlock\">task_unlock</a>(<a class=\"id\" href=\"#current\">current</a>);", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#allowed\">allowed</a> = <a class=\"id\" href=\"#node_isset\">node_isset</a>(<a class=\"id\" href=\"#node\">node</a>, <a class=\"id\" href=\"#cs\">cs</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#allowed\">allowed</a>;", 
"}", 
"", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * cpuset_node_allowed_hardwall - Can we allocate on a memory node?</span>", 
"<span class=\"comment\"> * @node: is this an allowed node?</span>", 
"<span class=\"comment\"> * @gfp_mask: memory allocation flags</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * If we're in interrupt, yes, we can always allocate.  If __GFP_THISNODE is</span>", 
"<span class=\"comment\"> * set, yes, we can always allocate.  If node is in our task's mems_allowed,</span>", 
"<span class=\"comment\"> * yes.  If the task has been OOM killed and has access to memory reserves as</span>", 
"<span class=\"comment\"> * specified by the TIF_MEMDIE flag, yes.</span>", 
"<span class=\"comment\"> * Otherwise, no.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * The __GFP_THISNODE placement logic is really handled elsewhere,</span>", 
"<span class=\"comment\"> * by forcibly using a zonelist starting at a specified node, and by</span>", 
"<span class=\"comment\"> * (in get_page_from_freelist()) refusing to consider the zones for</span>", 
"<span class=\"comment\"> * any node on the zonelist except the first.  By the time any such</span>", 
"<span class=\"comment\"> * calls get to this routine, we should just shut up and say 'yes'.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Unlike the cpuset_node_allowed_softwall() variant, above,</span>", 
"<span class=\"comment\"> * this variant requires that the node be in the current task's</span>", 
"<span class=\"comment\"> * mems_allowed or that we're in interrupt.  It does not scan up the</span>", 
"<span class=\"comment\"> * cpuset hierarchy for the nearest enclosing mem_exclusive cpuset.</span>", 
"<span class=\"comment\"> * It never sleeps.</span>", 
"<span class=\"comment\"> */</span>", 
"int <a class=\"id\" href=\"#__cpuset_node_allowed_hardwall\">__cpuset_node_allowed_hardwall</a>(int <a class=\"id\" href=\"#node\">node</a>, <a class=\"id\" href=\"#gfp_t\">gfp_t</a> <a class=\"id\" href=\"#gfp_mask\">gfp_mask</a>)", 
"{", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#in_interrupt\">in_interrupt</a>() || (<a class=\"id\" href=\"#gfp_mask\">gfp_mask</a> &amp; <a class=\"id\" href=\"#__GFP_THISNODE\">__GFP_THISNODE</a>))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#node_isset\">node_isset</a>(<a class=\"id\" href=\"#node\">node</a>, <a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/><span class=\"comment\">/*</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * Allow tasks that have access to memory reserves because they have</span>", 
"<span class=\"comment\"><span class=\"ts\"/> * been OOM killed to get memory anywhere.</span>", 
"<span class=\"comment\"><span class=\"ts\"/> */</span>", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#unlikely\">unlikely</a>(<a class=\"id\" href=\"#test_thread_flag\">test_thread_flag</a>(<a class=\"id\" href=\"#TIF_MEMDIE\">TIF_MEMDIE</a>)))", 
"<span class=\"ts\"/><span class=\"ts\"/>return 1;", 
"<span class=\"ts\"/>return 0;", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_unlock - release lock on cpuset changes</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Undo the lock taken in a previous cpuset_lock() call.</span>", 
"<span class=\"comment\"> */</span>", 
"", 
"void <a class=\"id\" href=\"#cpuset_unlock\">cpuset_unlock</a>(void)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#mutex_unlock\">mutex_unlock</a>(&amp;<a class=\"id\" href=\"#callback_mutex\">callback_mutex</a>);", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_mem_spread_node() - On which node to begin search for a file page</span>", 
"<span class=\"comment\"> * cpuset_slab_spread_node() - On which node to begin search for a slab page</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * If a task is marked PF_SPREAD_PAGE or PF_SPREAD_SLAB (as for</span>", 
"<span class=\"comment\"> * tasks in a cpuset with is_spread_page or is_spread_slab set),</span>", 
"<span class=\"comment\"> * and if the memory allocation used cpuset_mem_spread_node()</span>", 
"<span class=\"comment\"> * to determine on which node to start looking, as it will for</span>", 
"<span class=\"comment\"> * certain page cache or slab cache pages such as used for file</span>", 
"<span class=\"comment\"> * system buffers and inode caches, then instead of starting on the</span>", 
"<span class=\"comment\"> * local node to look for a free page, rather spread the starting</span>", 
"<span class=\"comment\"> * node around the tasks mems_allowed nodes.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * We don't have to worry about the returned node being offline</span>", 
"<span class=\"comment\"> * because \"it can't happen\", and even if it did, it would be ok.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * The routines calling guarantee_online_mems() are careful to</span>", 
"<span class=\"comment\"> * only set nodes in task-&gt;mems_allowed that are online.  So it</span>", 
"<span class=\"comment\"> * should not be possible for the following code to return an</span>", 
"<span class=\"comment\"> * offline node.  But if it did, that would be ok, as this routine</span>", 
"<span class=\"comment\"> * is not returning the node where the allocation must be, only</span>", 
"<span class=\"comment\"> * the node where the search should start.  The zonelist passed to</span>", 
"<span class=\"comment\"> * __alloc_pages() will include all nodes.  If the slab allocator</span>", 
"<span class=\"comment\"> * is passed an offline node, it will fall back to the local node.</span>", 
"<span class=\"comment\"> * See kmem_cache_alloc_node().</span>", 
"<span class=\"comment\"> */</span>", 
"", 
"static int <a class=\"id\" href=\"#cpuset_spread_node\">cpuset_spread_node</a>(int *<a class=\"id\" href=\"#rotor\">rotor</a>)", 
"{", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#node\">node</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#node\">node</a> = <a class=\"id\" href=\"#next_node\">next_node</a>(*<a class=\"id\" href=\"#rotor\">rotor</a>, <a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#node\">node</a> == <a class=\"id\" href=\"#MAX_NUMNODES\">MAX_NUMNODES</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/><a class=\"id\" href=\"#node\">node</a> = <a class=\"id\" href=\"#first_node\">first_node</a>(<a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/>*<a class=\"id\" href=\"#rotor\">rotor</a> = <a class=\"id\" href=\"#node\">node</a>;", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#node\">node</a>;", 
"}", 
"", 
"int <a class=\"id\" href=\"#cpuset_mem_spread_node\">cpuset_mem_spread_node</a>(void)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#cpuset_spread_node\">cpuset_spread_node</a>(&amp;<a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#cpuset_mem_spread_rotor\">cpuset_mem_spread_rotor</a>);", 
"}", 
"", 
"int <a class=\"id\" href=\"#cpuset_slab_spread_node\">cpuset_slab_spread_node</a>(void)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#cpuset_spread_node\">cpuset_spread_node</a>(&amp;<a class=\"id\" href=\"#current\">current</a>-><a class=\"id\" href=\"#cpuset_slab_spread_rotor\">cpuset_slab_spread_rotor</a>);", 
"}", 
"", 
"<a class=\"id\" href=\"#EXPORT_SYMBOL_GPL\">EXPORT_SYMBOL_GPL</a>(<a class=\"id\" href=\"#cpuset_mem_spread_node\">cpuset_mem_spread_node</a>);", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_mems_allowed_intersects - Does @tsk1's mems_allowed intersect @tsk2's?</span>", 
"<span class=\"comment\"> * @tsk1: pointer to task_struct of some task.</span>", 
"<span class=\"comment\"> * @tsk2: pointer to task_struct of some other task.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Description: Return true if @tsk1's mems_allowed intersects the</span>", 
"<span class=\"comment\"> * mems_allowed of @tsk2.  Used by the OOM killer to determine if</span>", 
"<span class=\"comment\"> * one of the task's memory usage might impact the memory available</span>", 
"<span class=\"comment\"> * to the other.</span>", 
"<span class=\"comment\"> **/</span>", 
"", 
"int <a class=\"id\" href=\"#cpuset_mems_allowed_intersects\">cpuset_mems_allowed_intersects</a>(const struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk1\">tsk1</a>,", 
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/>   const struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk2\">tsk2</a>)", 
"{", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#nodes_intersects\">nodes_intersects</a>(<a class=\"id\" href=\"#tsk1\">tsk1</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>, <a class=\"id\" href=\"#tsk2\">tsk2</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"}", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_print_task_mems_allowed - prints task's cpuset and mems_allowed</span>", 
"<span class=\"comment\"> * @task: pointer to task_struct of some task.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Description: Prints @task's name, cpuset name, and cached copy of its</span>", 
"<span class=\"comment\"> * mems_allowed to the kernel log.  Must hold task_lock(task) to allow</span>", 
"<span class=\"comment\"> * dereferencing task_cs(task).</span>", 
"<span class=\"comment\"> */</span>", 
"void <a class=\"id\" href=\"#cpuset_print_task_mems_allowed\">cpuset_print_task_mems_allowed</a>(struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk\">tsk</a>)", 
"{", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#dentry\">dentry</a> *<a class=\"id\" href=\"#dentry\">dentry</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#dentry\">dentry</a> = <a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#tsk\">tsk</a>)-><a class=\"id\" href=\"#css\">css</a>.<a class=\"id\" href=\"#cgroup\">cgroup</a>-><a class=\"id\" href=\"#dentry\">dentry</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#spin_lock\">spin_lock</a>(&amp;<a class=\"id\" href=\"#cpuset_buffer_lock\">cpuset_buffer_lock</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#snprintf\">snprintf</a>(<a class=\"id\" href=\"#cpuset_name\">cpuset_name</a>, <a class=\"id\" href=\"#CPUSET_NAME_LEN\">CPUSET_NAME_LEN</a>,", 
"<span class=\"ts\"/><span class=\"ts\"/> <a class=\"id\" href=\"#dentry\">dentry</a> ? (const char *)<a class=\"id\" href=\"#dentry\">dentry</a>-><a class=\"id\" href=\"#d_name\">d_name</a>.<a class=\"id\" href=\"#name\">name</a> : \"/\");", 
"<span class=\"ts\"/><a class=\"id\" href=\"#nodelist_scnprintf\">nodelist_scnprintf</a>(<a class=\"id\" href=\"#cpuset_nodelist\">cpuset_nodelist</a>, <a class=\"id\" href=\"#CPUSET_NODELIST_LEN\">CPUSET_NODELIST_LEN</a>,", 
"<span class=\"ts\"/><span class=\"ts\"/><span class=\"ts\"/>   <a class=\"id\" href=\"#tsk\">tsk</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#printk\">printk</a>(<a class=\"id\" href=\"#KERN_INFO\">KERN_INFO</a> \"%s cpuset=%s mems_allowed=%s\\n\",", 
"<span class=\"ts\"/>       <a class=\"id\" href=\"#tsk\">tsk</a>-><a class=\"id\" href=\"#comm\">comm</a>, <a class=\"id\" href=\"#cpuset_name\">cpuset_name</a>, <a class=\"id\" href=\"#cpuset_nodelist\">cpuset_nodelist</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#spin_unlock\">spin_unlock</a>(&amp;<a class=\"id\" href=\"#cpuset_buffer_lock\">cpuset_buffer_lock</a>);", 
"}", 
"", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * Collection of memory_pressure is suppressed unless</span>", 
"<span class=\"comment\"> * this flag is enabled by writing \"1\" to the special</span>", 
"<span class=\"comment\"> * cpuset file 'memory_pressure_enabled' in the root cpuset.</span>", 
"<span class=\"comment\"> */</span>", 
"", 
"int <a class=\"id\" href=\"#cpuset_memory_pressure_enabled\">cpuset_memory_pressure_enabled</a> <a class=\"id\" href=\"#__read_mostly\">__read_mostly</a>;", 
"", 
"<span class=\"comment\">/**</span>", 
"<span class=\"comment\"> * cpuset_memory_pressure_bump - keep stats of per-cpuset reclaims.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Keep a running average of the rate of synchronous (direct)</span>", 
"<span class=\"comment\"> * page reclaim efforts initiated by tasks in each cpuset.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * This represents the rate at which some task in the cpuset</span>", 
"<span class=\"comment\"> * ran low on memory on all nodes it was allowed to use, and</span>", 
"<span class=\"comment\"> * had to enter the kernels page reclaim code in an effort to</span>", 
"<span class=\"comment\"> * create more free memory by tossing clean pages or swapping</span>", 
"<span class=\"comment\"> * or writing dirty pages.</span>", 
"<span class=\"comment\"> *</span>", 
"<span class=\"comment\"> * Display to user space in the per-cpuset read-only file</span>", 
"<span class=\"comment\"> * \"memory_pressure\".  Value displayed is an integer</span>", 
"<span class=\"comment\"> * representing the recent rate of entry into the synchronous</span>", 
"<span class=\"comment\"> * (direct) page reclaim by any task attached to the cpuset.</span>", 
"<span class=\"comment\"> **/</span>", 
"", 
"void <a class=\"id\" href=\"#__cpuset_memory_pressure_bump\">__cpuset_memory_pressure_bump</a>(void)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_lock\">task_lock</a>(<a class=\"id\" href=\"#current\">current</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#fmeter_markevent\">fmeter_markevent</a>(&amp;<a class=\"id\" href=\"#task_cs\">task_cs</a>(<a class=\"id\" href=\"#current\">current</a>)-><a class=\"id\" href=\"#fmeter\">fmeter</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#task_unlock\">task_unlock</a>(<a class=\"id\" href=\"#current\">current</a>);", 
"}", 
"", 
"#<a class=\"id\" href=\"#ifdef\">ifdef</a> <a class=\"id\" href=\"#CONFIG_PROC_PID_CPUSET\">CONFIG_PROC_PID_CPUSET</a>", 
"<span class=\"comment\">/*</span>", 
"<span class=\"comment\"> * proc_cpuset_show()</span>", 
"<span class=\"comment\"> *  - Print tasks cpuset path into seq_file.</span>", 
"<span class=\"comment\"> *  - Used for /proc/&lt;pid&gt;/cpuset.</span>", 
"<span class=\"comment\"> *  - No need to task_lock(tsk) on this tsk-&gt;cpuset reference, as it</span>", 
"<span class=\"comment\"> *    doesn't really matter if tsk-&gt;cpuset changes after we read it,</span>", 
"<span class=\"comment\"> *    and we take cgroup_mutex, keeping cpuset_attach() from changing it</span>", 
"<span class=\"comment\"> *    anyway.</span>", 
"<span class=\"comment\"> */</span>", 
"static int <a class=\"id\" href=\"#proc_cpuset_show\">proc_cpuset_show</a>(struct <a class=\"id\" href=\"#seq_file\">seq_file</a> *<a class=\"id\" href=\"#m\">m</a>, void *<a class=\"id\" href=\"#unused_v\">unused_v</a>)", 
"{", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#pid\">pid</a> *<a class=\"id\" href=\"#pid\">pid</a>;", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#tsk\">tsk</a>;", 
"<span class=\"ts\"/>char *<a class=\"id\" href=\"#buf\">buf</a>;", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#cgroup_subsys_state\">cgroup_subsys_state</a> *<a class=\"id\" href=\"#css\">css</a>;", 
"<span class=\"ts\"/>int <a class=\"id\" href=\"#retval\">retval</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#retval\">retval</a> = -<a class=\"id\" href=\"#ENOMEM\">ENOMEM</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#buf\">buf</a> = <a class=\"id\" href=\"#kmalloc\">kmalloc</a>(<a class=\"id\" href=\"#PAGE_SIZE\">PAGE_SIZE</a>, <a class=\"id\" href=\"#GFP_KERNEL\">GFP_KERNEL</a>);", 
"<span class=\"ts\"/>if (!<a class=\"id\" href=\"#buf\">buf</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/>goto <a class=\"id\" href=\"#out\">out</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#retval\">retval</a> = -<a class=\"id\" href=\"#ESRCH\">ESRCH</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#pid\">pid</a> = <a class=\"id\" href=\"#m\">m</a>-><a class=\"id\" href=\"#private\">private</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#tsk\">tsk</a> = <a class=\"id\" href=\"#get_pid_task\">get_pid_task</a>(<a class=\"id\" href=\"#pid\">pid</a>, <a class=\"id\" href=\"#PIDTYPE_PID\">PIDTYPE_PID</a>);", 
"<span class=\"ts\"/>if (!<a class=\"id\" href=\"#tsk\">tsk</a>)", 
"<span class=\"ts\"/><span class=\"ts\"/>goto <a class=\"id\" href=\"#out_free\">out_free</a>;", 
"", 
"<span class=\"ts\"/><a class=\"id\" href=\"#retval\">retval</a> = -<a class=\"id\" href=\"#EINVAL\">EINVAL</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_lock\">cgroup_lock</a>();", 
"<span class=\"ts\"/><a class=\"id\" href=\"#css\">css</a> = <a class=\"id\" href=\"#task_subsys_state\">task_subsys_state</a>(<a class=\"id\" href=\"#tsk\">tsk</a>, <a class=\"id\" href=\"#cpuset_subsys_id\">cpuset_subsys_id</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#retval\">retval</a> = <a class=\"id\" href=\"#cgroup_path\">cgroup_path</a>(<a class=\"id\" href=\"#css\">css</a>-><a class=\"id\" href=\"#cgroup\">cgroup</a>, <a class=\"id\" href=\"#buf\">buf</a>, <a class=\"id\" href=\"#PAGE_SIZE\">PAGE_SIZE</a>);", 
"<span class=\"ts\"/>if (<a class=\"id\" href=\"#retval\">retval</a> &lt; 0)", 
"<span class=\"ts\"/><span class=\"ts\"/>goto <a class=\"id\" href=\"#out_unlock\">out_unlock</a>;", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_puts\">seq_puts</a>(<a class=\"id\" href=\"#m\">m</a>, <a class=\"id\" href=\"#buf\">buf</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_putc\">seq_putc</a>(<a class=\"id\" href=\"#m\">m</a>, '\\n');", 
"<a class=\"id\" href=\"#out_unlock\">out_unlock</a>:", 
"<span class=\"ts\"/><a class=\"id\" href=\"#cgroup_unlock\">cgroup_unlock</a>();", 
"<span class=\"ts\"/><a class=\"id\" href=\"#put_task_struct\">put_task_struct</a>(<a class=\"id\" href=\"#tsk\">tsk</a>);", 
"<a class=\"id\" href=\"#out_free\">out_free</a>:", 
"<span class=\"ts\"/><a class=\"id\" href=\"#kfree\">kfree</a>(<a class=\"id\" href=\"#buf\">buf</a>);", 
"<a class=\"id\" href=\"#out\">out</a>:", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#retval\">retval</a>;", 
"}", 
"", 
"static int <a class=\"id\" href=\"#cpuset_open\">cpuset_open</a>(struct <a class=\"id\" href=\"#inode\">inode</a> *<a class=\"id\" href=\"#inode\">inode</a>, struct <a class=\"id\" href=\"#file\">file</a> *<a class=\"id\" href=\"#file\">file</a>)", 
"{", 
"<span class=\"ts\"/>struct <a class=\"id\" href=\"#pid\">pid</a> *<a class=\"id\" href=\"#pid\">pid</a> = <a class=\"id\" href=\"#PROC_I\">PROC_I</a>(<a class=\"id\" href=\"#inode\">inode</a>)-><a class=\"id\" href=\"#pid\">pid</a>;", 
"<span class=\"ts\"/>return <a class=\"id\" href=\"#single_open\">single_open</a>(<a class=\"id\" href=\"#file\">file</a>, <a class=\"id\" href=\"#proc_cpuset_show\">proc_cpuset_show</a>, <a class=\"id\" href=\"#pid\">pid</a>);", 
"}", 
"", 
"const struct <a class=\"id\" href=\"#file_operations\">file_operations</a> <a class=\"id\" href=\"#proc_cpuset_operations\">proc_cpuset_operations</a> = {", 
"<span class=\"ts\"/>.<a class=\"id\" href=\"#open\">open</a><span class=\"ts\"/><span class=\"ts\"/>= <a class=\"id\" href=\"#cpuset_open\">cpuset_open</a>,", 
"<span class=\"ts\"/>.<a class=\"id\" href=\"#read\">read</a><span class=\"ts\"/><span class=\"ts\"/>= <a class=\"id\" href=\"#seq_read\">seq_read</a>,", 
"<span class=\"ts\"/>.<a class=\"id\" href=\"#llseek\">llseek</a><span class=\"ts\"/><span class=\"ts\"/>= <a class=\"id\" href=\"#seq_lseek\">seq_lseek</a>,", 
"<span class=\"ts\"/>.<a class=\"id\" href=\"#release\">release</a><span class=\"ts\"/>= <a class=\"id\" href=\"#single_release\">single_release</a>,", 
"};", 
"#<a class=\"id\" href=\"#endif\">endif</a> <span class=\"comment\">/* CONFIG_PROC_PID_CPUSET */</span>", 
"", 
"<span class=\"comment\">/* Display task mems_allowed in /proc/&lt;pid&gt;/status file. */</span>", 
"void <a class=\"id\" href=\"#cpuset_task_status_allowed\">cpuset_task_status_allowed</a>(struct <a class=\"id\" href=\"#seq_file\">seq_file</a> *<a class=\"id\" href=\"#m\">m</a>, struct <a class=\"id\" href=\"#task_struct\">task_struct</a> *<a class=\"id\" href=\"#task\">task</a>)", 
"{", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_printf\">seq_printf</a>(<a class=\"id\" href=\"#m\">m</a>, \"Mems_allowed:\\t\");", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_nodemask\">seq_nodemask</a>(<a class=\"id\" href=\"#m\">m</a>, &amp;<a class=\"id\" href=\"#task\">task</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_printf\">seq_printf</a>(<a class=\"id\" href=\"#m\">m</a>, \"\\n\");", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_printf\">seq_printf</a>(<a class=\"id\" href=\"#m\">m</a>, \"Mems_allowed_list:\\t\");", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_nodemask_list\">seq_nodemask_list</a>(<a class=\"id\" href=\"#m\">m</a>, &amp;<a class=\"id\" href=\"#task\">task</a>-><a class=\"id\" href=\"#mems_allowed\">mems_allowed</a>);", 
"<span class=\"ts\"/><a class=\"id\" href=\"#seq_printf\">seq_printf</a>(<a class=\"id\" href=\"#m\">m</a>, \"\\n\");", 
"}", 
];
xr_frag_insert('l/b4/0720c08ab6dc631ce6f1f78d71ca75e40077b0.xr', __xr_tmp);
